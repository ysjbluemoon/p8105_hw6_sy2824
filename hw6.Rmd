---
title: "hw6"
author: "Sijia Yue"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)
```
## Problem 1
```{r}
# Read file into the project
file = read_csv("file/homicide-data.csv") %>% 
  janitor::clean_names() 
```

```{r}
homicide_data = 
  file %>% 
  # Add new variable city_state
  mutate(city_state = str_c(city, ", " , state)) %>% 
  mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ" , "Kansas City, MO" , "Tulsa, AL")) %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white"), victim_race = fct_relevel(victim_race, "white")) %>% 
  mutate(victim_age = as.numeric(victim_age))
  
```

Fit in logistics regression model
```{r}
# Filter Baltimore from the list
baltimore_df = 
  homicide_data %>% 
  filter(city == "Baltimore")

# Fit into the logistic regression model with age, sex and race
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

# Estimate, CI of adjusted odds ratio
broom::tidy(fit_logistic, conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(OR = estimate) %>%
  select(term, OR, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)

```

Mapping into all cities
```{r, warning=FALSE}
glm_or = function(cities){
  fit_logistic =   
  glm(resolved ~ victim_age + victim_sex + victim_race, data = cities, family = binomial())
  
  broom::tidy(fit_logistic, conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(OR = estimate) %>%
  select(term, OR, conf.low, conf.high) 
}

glm_result = 
  homicide_data %>% 
  group_by(city_state) %>% 
  select(city_state, victim_race:victim_sex, resolved) %>% 
  nest() %>% 
  # Using the map function to do the iteration
  mutate(result = map(data, glm_or)) %>% 
  select(-data) %>% 
  unnest() %>% 
  select(-term)
```

Plot the OR and CI 
```{r}
glm_result %>%  
  mutate(city_state = as.factor(city_state)) %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR, ymin = conf.low, ymax = conf.high, color = city_state)) +
  geom_point() +
  geom_errorbar() +
  labs(
    title = "Plot of Odd Ratio and CI for each city",
    x = "Each city and its state",
    y = "Odd Ratio and its CI"
  ) +
  theme_bw() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1)) 
```

## Problem 2
### Data cleaning
```{r}
# Read data into project and data cleaning
birth_data = read_csv("file/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  # mutating the elements into factor since they are categorical data
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
```

### Fit in my model
First, read the file into R project and explore the correlation using `cor()`.
```{r}
# Run cor() to have a brief overview of the correlation of predictors.
read_csv("file/birthweight.csv") %>% 
  select(-pnumlbw, -pnumsga) %>% 
  cor() %>% 
  broom::tidy()
```

Then, I try to fit all the variables to figure out the fit.
```{r}
fit_all = 
  lm(bwt ~ ., data = birth_data)

summary(fit_all)
```
The adjusted r square is 0.717, which means it is a good fit. However, the variables are too many so it would have the chance to be over fitted. So, I will choose the variable according to the p value. 

Then, I try to fit in the model with p value extremely equal to zero. 
```{r}
fit_model1 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + smoken 
                , data = birth_data)

summary(fit_model1)
```
We could see that the adjusted R square decreases to 0.697. So, I would add some more variable that p value less than 0.01.

```{r}
fit_model2 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + smoken 
                , data = birth_data)

summary(fit_model2)
```

The adjusted R square increases to 0.7138, so model 2 is better than model 1. 

Then, I will try to add more variable which p value is less than 0.05.

```{r}
fit_model3 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken 
                , data = birth_data)

summary(fit_model3)
```

The adjusted R square still increases to 0.7142, so model 3 is better than model 2. I will use model 3 as my model.

```{r}
fit_model = fit_model3
```

### Ploting
show a plot of model residuals against fitted values â€“ use add_predictions and add_residuals in making this plot
```{r}
# plot reseduals against fitted values
birth_data %>% 
  modelr::add_residuals(fit_model) %>% 
  modelr::add_predictions(fit_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE) +
  labs(
      x = "Fitted Value",
      y = "Residual",
      title = "Model residuals against predictied values"
  )
```
As shown in the plot, my model is not performing very well when the predicted value is less than 200, where the residuals are pretty high. However, as the predicted value grows, the residuals become steady and decreases. When the predicted valus is around 2000 and 4000, the residuals are gathered around 0, indicating the model fits well in this range. 

### Comparing two model
One using length at birth and gestational age as predictors (main effects only)
```{r}
fit_compare1 = 
  lm(bwt ~  blength + gaweeks, data = birth_data)

summary(fit_compare1)
```

One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
fit_compare2 =
  lm(bwt ~  bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth_data)

summary(fit_compare2)
```

Use cross validation to compare three models.
```{r}
# use cross_mc to form the train and test dataset.
cv_df = 
  crossv_mc(birth_data, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

# use map() to run the cross validation process
cv_df = 
  cv_df %>% 
  mutate(fit_model    = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken, data = .x)),
         fit_compare1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         fit_compare2 = map(train, ~lm(bwt ~  bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_model    = map2_dbl(fit_model, test, ~rmse(model = .x, data = .y)),
         rmse_compare1 = map2_dbl(fit_compare1, test, ~rmse(model = .x, data = .y)),
         rmse_compare2 = map2_dbl(fit_compare2, test, ~rmse(model = .x, data = .y)))
```

Plot the standard error of the three models to compare the fitting.
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "Violin plots of RMSE", 
       x = "Model", 
       y = "RMSE")
```

As the violin plot shows, model 1 has the highest RMSE since the model predictors are too simple. For model 2, the RMSE seems lower than the first model which matches the result that the model adds the interaction of three prodictors. The model I fit in preforms better because it has the lowest RMSE.