---
title: "hw6"
author: "Sijia Yue"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)
```
## Problem 1
```{r}
# Read file into the project
file = read_csv("file/homicide-data.csv") %>% 
  janitor::clean_names() 
```

```{r}
homicide_data = 
  file %>% 
  # Add new variable city_state
  mutate(city_state = str_c(city, ", " , state)) %>% 
  mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ" , "Kansas City, MO" , "Tulsa, AL")) %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white"), victim_race = fct_relevel(victim_race, "white")) %>% 
  mutate(victim_age = as.numeric(victim_age))
  
```

Fit in logistics regression model
```{r}
# Filter Baltimore from the list
baltimore_df = 
  homicide_data %>% 
  filter(city == "Baltimore")

# Fit into the logistic regression model with age, sex and race
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

# Estimate, CI of adjusted odds ratio
broom::tidy(fit_logistic, conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(OR = estimate) %>%
  select(term, OR, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)

```

Mapping into all cities
```{r, warning=FALSE}
glm_or = function(cities){
  fit_logistic =   
  glm(resolved ~ victim_age + victim_sex + victim_race, data = cities, family = binomial())
  
  broom::tidy(fit_logistic, conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(OR = estimate) %>%
  select(term, OR, conf.low, conf.high) 
}

glm_result = 
  homicide_data %>% 
  group_by(city_state) %>% 
  select(city_state, victim_race:victim_sex, resolved) %>% 
  nest() %>% 
  # Using the map function to do the iteration
  mutate(result = map(data, glm_or)) %>% 
  select(-data) %>% 
  unnest() %>% 
  select(-term)
```

Plot the OR and CI 
```{r}
glm_result %>%  
  mutate(city_state = as.factor(city_state)) %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR, ymin = conf.low, ymax = conf.high, color = city_state)) +
  geom_point() +
  geom_errorbar() +
  labs(
    title = "Plot of Odd Ratio and CI for each city",
    x = "Each city and its state",
    y = "Odd Ratio and its CI"
  ) +
  theme_bw() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1)) 
```

## Problem 2
### Data cleaning
```{r}
birth_data = read_csv("file/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
```

### Fit in my model
First, read the file into R project and explore the correlation using `cor()`.
```{r}
read_csv("file/birthweight.csv") %>% 
  select(-pnumlbw, -pnumsga) %>% 
  cor() %>% 
  broom::tidy()
```

Then, I try to fit all the variables to figure out the fit.
```{r}
fit_all = 
  lm(bwt ~ ., data = birth_data)

summary(fit_all)
```
The adjusted r square is 0.717, which means it is a good fit. However, the variables are too many so it would have the chance to be over fitted. So, I will choose the variable according to the p value. 

Then, I try to fit in the model with p value extremely equal to zero. 
```{r}
fit_model1 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + smoken 
                , data = birth_data)

summary(fit_model1)
```
We could see that the adjusted R square decreases to 0.697. So, I would add some more variable that p value less than 0.01.

```{r}
fit_model2 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + smoken 
                , data = birth_data)

summary(fit_model2)
```

The adjusted R square increases to 0.7138, so model 2 is better than model 1. 

Then, I will try to add more variable which p value is less than 0.05.

```{r}
fit_model3 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken 
                , data = birth_data)

summary(fit_model3)
```

The adjusted R square still increases to 0.7142, so model 3 is better than model 2. I will use model 3 as my model.

```{r}
fit_model = fit_model3
```

### Ploting
```{r}
modelr::add_residuals(birth_data, fit_model)
modelr::add_predictions(birth_data, fit_model)

birth_data %>% 
  modelr::add_residuals(fit_model) %>% 
  modelr::add_predictions(fit_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
   geom_point(alpha = 0.3) +
  labs(
      x = "Predicted Value",
      y = "Residual",
      title = "Model residuals against predictied values"
  )
```

### Comparing two model
```{r}
fit_compare1 = 
  lm(bwt ~  blength + gaweeks, data = birth_data)

summary(fit_compare1)
```

```{r}
fit_compare2 =
  lm(bwt ~  bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth_data)

summary(fit_compare2)
```

Use cross validation to compare three models.
```{r}
cv_df = 
  crossv_mc(birth_data, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(fit_model    = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken, data = .x)),
         fit_compare1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         fit_compare2 = map(train, ~lm(bwt ~  bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_model    = map2_dbl(fit_model, test, ~rmse(model = .x, data = .y)),
         rmse_compare1 = map2_dbl(fit_compare1, test, ~rmse(model = .x, data = .y)),
         rmse_compare2 = map2_dbl(fit_compare2, test, ~rmse(model = .x, data = .y)))
```

Plot the standard error of the three models to compare the fitting.
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

